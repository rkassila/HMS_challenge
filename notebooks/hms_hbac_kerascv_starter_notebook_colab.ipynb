{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rkassila/HMS_challenge/blob/master/notebooks/hms_hbac_kerascv_starter_notebook_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-10T05:24:31.308329Z",
          "iopub.status.busy": "2024-01-10T05:24:31.307595Z",
          "iopub.status.idle": "2024-01-10T05:24:31.313088Z",
          "shell.execute_reply": "2024-01-10T05:24:31.312113Z",
          "shell.execute_reply.started": "2024-01-10T05:24:31.308287Z"
        },
        "papermill": {
          "duration": 0.011755,
          "end_time": "2024-01-14T03:16:16.447481",
          "exception": false,
          "start_time": "2024-01-14T03:16:16.435726",
          "status": "completed"
        },
        "tags": [],
        "id": "t1xtJW779mSk"
      },
      "source": [
        "<center><img src=\"https://keras.io/img/logo-small.png\" alt=\"Keras logo\" width=\"100\"><br/>\n",
        "This starter notebook is provided by the Keras team.</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXThnGoB9mSp"
      },
      "source": [
        "# HMS - Harmful Brain Activity Classification with [KerasCV](https://github.com/keras-team/keras-cv) and [Keras](https://github.com/keras-team/keras)\n",
        "\n",
        "> The objective of this competition is to classify seizures and other patterns of harmful brain activity in critically ill patients\n",
        "\n",
        "This notebook guides you through the process of training and inferring a Deep Learning model, specifically EfficientNetV2, using KerasCV on the competition dataset. Specificaclly, this notebook uses spectrogram of the eeg data to classify the patterns.\n",
        "\n",
        "Fun fact: This notebook is backend-agnostic, supporting TensorFlow, PyTorch, and JAX. Utilizing KerasCV and Keras allows us to choose our preferred backend. Explore more details on [Keras](https://keras.io/keras_core/announcement/).\n",
        "\n",
        "In this notebook, you will learn:\n",
        "\n",
        "* Loading the data efficiently using [`tf.data`](https://www.tensorflow.org/guide/data).\n",
        "* Creating the model using KerasCV presets.\n",
        "* Training the model.\n",
        "* Inference and Submission on test data.\n",
        "\n",
        "**Note**: For a more in-depth understanding of KerasCV, refer to the [KerasCV guides](https://keras.io/guides/keras_cv/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.011416,
          "end_time": "2024-01-14T03:16:16.470167",
          "exception": false,
          "start_time": "2024-01-14T03:16:16.458751",
          "status": "completed"
        },
        "tags": [],
        "id": "aodUOQeo9mSq"
      },
      "source": [
        "# 🛠 | Install Libraries  \n",
        "\n",
        "Since internet access is **disabled** during inference, we cannot install libraries in the usual `!pip install <lib_name>` manner. Instead, we need to install libraries from local files. In the following cell, we will install libraries from our local files. The installation code stays very similar - we just use the `filepath` instead of the `filename` of the library. So now the code is `!pip install <local_filepath>`.\n",
        "\n",
        "> The `filepath` of these local libraries look quite complicated, but don't be intimidated! Also `--no-deps` argument ensures that we are not installing any additional libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-01T08:09:58.472046Z",
          "iopub.status.busy": "2024-02-01T08:09:58.471669Z",
          "iopub.status.idle": "2024-02-01T08:11:45.612735Z",
          "shell.execute_reply": "2024-02-01T08:11:45.611628Z",
          "shell.execute_reply.started": "2024-02-01T08:09:58.472001Z"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELwFa7hq9mSq",
        "outputId": "05fe944e-d819-47c7-cfed-7c6da436631f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_cv\n",
            "  Downloading keras_cv-0.8.2-py3-none-any.whl (613 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/613.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/613.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.1/613.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_cv) (24.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras_cv) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_cv) (2023.12.25)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras_cv) (4.9.4)\n",
            "Collecting keras-core (from keras_cv)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras_cv) (0.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (13.7.1)\n",
            "Collecting namex (from keras-core->keras_cv)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (0.1.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (5.9.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.14.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (6.3.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (4.10.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (3.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (2024.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets->keras_cv) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_cv) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_cv) (2.16.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv) (1.63.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras_cv) (0.1.2)\n",
            "Installing collected packages: namex, keras-core, keras_cv\n",
            "Successfully installed keras-core-0.1.7 keras_cv-0.8.2 namex-0.0.7\n"
          ]
        }
      ],
      "source": [
        "#!pip install -q /kaggle/input/kerasv3-lib-ds/keras_cv-0.8.2-py3-none-any.whl --no-deps\n",
        "#!pip install -q /kaggle/input/kerasv3-lib-ds/tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl --no-deps\n",
        "#!pip install -q /kaggle/input/kerasv3-lib-ds/keras-3.0.4-py3-none-any.whl --no-deps\n",
        "\n",
        "!pip install keras_cv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.010878,
          "end_time": "2024-01-14T03:17:49.510159",
          "exception": false,
          "start_time": "2024-01-14T03:17:49.499281",
          "status": "completed"
        },
        "tags": [],
        "id": "BZtObw0W9mSs"
      },
      "source": [
        "# 📚 | Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jxTIIeH9mSs",
        "outputId": "b5dbde11-0d0f-4eb2-baa1-3579cd635dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.23)\n",
            "Collecting jax\n",
            "  Downloading jax-0.4.25-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (0.4.23+cuda12.cudnn89)\n",
            "Collecting jaxlib\n",
            "  Downloading jaxlib-0.4.25-cp310-cp310-manylinux2014_x86_64.whl (79.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax) (1.11.4)\n",
            "Installing collected packages: jaxlib, jax\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.23+cuda12.cudnn89\n",
            "    Uninstalling jaxlib-0.4.23+cuda12.cudnn89:\n",
            "      Successfully uninstalled jaxlib-0.4.23+cuda12.cudnn89\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.23\n",
            "    Uninstalling jax-0.4.23:\n",
            "      Successfully uninstalled jax-0.4.23\n",
            "Successfully installed jax-0.4.25 jaxlib-0.4.25\n"
          ]
        }
      ],
      "source": [
        "!pip install -U jax jaxlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2024-02-01T08:11:45.615026Z",
          "iopub.status.busy": "2024-02-01T08:11:45.614724Z",
          "iopub.status.idle": "2024-02-01T08:11:56.499875Z",
          "shell.execute_reply": "2024-02-01T08:11:56.499055Z",
          "shell.execute_reply.started": "2024-02-01T08:11:45.615Z"
        },
        "papermill": {
          "duration": 10.671979,
          "end_time": "2024-01-14T03:18:00.193134",
          "exception": false,
          "start_time": "2024-01-14T03:17:49.521155",
          "status": "completed"
        },
        "tags": [],
        "id": "4PQAfPLW9mSs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#os.environ[\"KERAS_BACKEND\"] = \"jax\" # you can also use tensorflow or torch\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import keras_cv\n",
        "import keras\n",
        "#from keras import ops\n",
        "from keras import backend as ops\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tqdm.notebook import tqdm\n",
        "import joblib\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.010958,
          "end_time": "2024-01-14T03:18:00.215704",
          "exception": false,
          "start_time": "2024-01-14T03:18:00.204746",
          "status": "completed"
        },
        "tags": [],
        "id": "tNFP5Ztv9mSt"
      },
      "source": [
        "## Library Versions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-01T08:11:56.501441Z",
          "iopub.status.busy": "2024-02-01T08:11:56.500924Z",
          "iopub.status.idle": "2024-02-01T08:11:56.506615Z",
          "shell.execute_reply": "2024-02-01T08:11:56.505678Z",
          "shell.execute_reply.started": "2024-02-01T08:11:56.501416Z"
        },
        "papermill": {
          "duration": 0.019435,
          "end_time": "2024-01-14T03:18:00.246368",
          "exception": false,
          "start_time": "2024-01-14T03:18:00.226933",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsU5FfkW9mSt",
        "outputId": "0599ca7b-e827-4186-c525-34b5b1fe2dfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow: 2.15.0\n",
            "Keras: 2.15.0\n",
            "KerasCV: 0.8.2\n"
          ]
        }
      ],
      "source": [
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"Keras:\", keras.__version__)\n",
        "print(\"KerasCV:\", keras_cv.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.010922,
          "end_time": "2024-01-14T03:18:00.26855",
          "exception": false,
          "start_time": "2024-01-14T03:18:00.257628",
          "status": "completed"
        },
        "tags": [],
        "id": "LQTAaiy99mSu"
      },
      "source": [
        "# ⚙️ | Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-01T08:11:56.510141Z",
          "iopub.status.busy": "2024-02-01T08:11:56.509498Z",
          "iopub.status.idle": "2024-02-01T08:11:56.526461Z",
          "shell.execute_reply": "2024-02-01T08:11:56.525619Z",
          "shell.execute_reply.started": "2024-02-01T08:11:56.51011Z"
        },
        "papermill": {
          "duration": 0.018795,
          "end_time": "2024-01-14T03:18:00.298534",
          "exception": false,
          "start_time": "2024-01-14T03:18:00.279739",
          "status": "completed"
        },
        "tags": [],
        "id": "JOcP_lzl9mSu"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    verbose = 1  # Verbosity\n",
        "    seed = 42  # Random seed\n",
        "    preset = \"efficientnetv2_b2_imagenet\"  # Name of pretrained classifier\n",
        "    image_size = [400, 300]  # Input image size\n",
        "    epochs = 13 # Training epochs\n",
        "    batch_size = 64  # Batch size\n",
        "    lr_mode = \"cos\" # LR scheduler mode from one of \"cos\", \"step\", \"exp\"\n",
        "    drop_remainder = True  # Drop incomplete batches\n",
        "    num_classes = 6 # Number of classes in the dataset\n",
        "    fold = 0 # Which fold to set as validation data\n",
        "    class_names = ['Seizure', 'LPD', 'GPD', 'LRDA','GRDA', 'Other']\n",
        "    label2name = dict(enumerate(class_names))\n",
        "    name2label = {v:k for k, v in label2name.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.010907,
          "end_time": "2024-01-14T03:18:00.32063",
          "exception": false,
          "start_time": "2024-01-14T03:18:00.309723",
          "status": "completed"
        },
        "tags": [],
        "id": "hGAJCHb69mSv"
      },
      "source": [
        "# ♻️ | Reproducibility\n",
        "Sets value for random seed to produce similar result in each run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-01T08:11:56.527893Z",
          "iopub.status.busy": "2024-02-01T08:11:56.527613Z",
          "iopub.status.idle": "2024-02-01T08:11:56.536142Z",
          "shell.execute_reply": "2024-02-01T08:11:56.535296Z",
          "shell.execute_reply.started": "2024-02-01T08:11:56.527869Z"
        },
        "papermill": {
          "duration": 0.018371,
          "end_time": "2024-01-14T03:18:00.350074",
          "exception": false,
          "start_time": "2024-01-14T03:18:00.331703",
          "status": "completed"
        },
        "tags": [],
        "id": "iQ8Y2ocm9mSv"
      },
      "outputs": [],
      "source": [
        "keras.utils.set_random_seed(CFG.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.010888,
          "end_time": "2024-01-14T03:18:00.372053",
          "exception": false,
          "start_time": "2024-01-14T03:18:00.361165",
          "status": "completed"
        },
        "tags": [],
        "id": "--A05-FJ9mSv"
      },
      "source": [
        "# 📁 | Dataset Path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSfEztBBF-zg",
        "outputId": "c5011f73-3105-45ce-a2f5-71e4197a8c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-01T08:11:56.5375Z",
          "iopub.status.busy": "2024-02-01T08:11:56.537196Z",
          "iopub.status.idle": "2024-02-01T08:11:56.548849Z",
          "shell.execute_reply": "2024-02-01T08:11:56.548017Z",
          "shell.execute_reply.started": "2024-02-01T08:11:56.537478Z"
        },
        "papermill": {
          "duration": 0.017704,
          "end_time": "2024-01-14T03:18:00.400852",
          "exception": false,
          "start_time": "2024-01-14T03:18:00.383148",
          "status": "completed"
        },
        "tags": [],
        "id": "GjBSPw9l9mSw"
      },
      "outputs": [],
      "source": [
        "#BASE_PATH = \"/kaggle/input/hms-harmful-brain-activity-classification\"\n",
        "BASE_PATH = \"../hms-harmful-brain-activity-classification\"\n",
        "\n",
        "\n",
        "SPEC_DIR = \"/tmp/dataset/hms-hbac\"\n",
        "os.makedirs(SPEC_DIR+'/train_spectrograms', exist_ok=True)\n",
        "os.makedirs(SPEC_DIR+'/test_spectrograms', exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.011434,
          "end_time": "2024-01-14T03:18:00.472401",
          "exception": false,
          "start_time": "2024-01-14T03:18:00.460967",
          "status": "completed"
        },
        "tags": [],
        "id": "Je9CvL349mSw"
      },
      "source": [
        "# 📖 | Meta Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-01T08:11:56.550129Z",
          "iopub.status.busy": "2024-02-01T08:11:56.549878Z",
          "iopub.status.idle": "2024-02-01T08:11:57.142269Z",
          "shell.execute_reply": "2024-02-01T08:11:57.141377Z",
          "shell.execute_reply.started": "2024-02-01T08:11:56.550108Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Ircmjx3Z9mSx",
        "outputId": "e2ed2769-7eb4-409f-d2c1-e6222e047ed2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../hms-harmful-brain-activity-classification/train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-0b1e71d12b1e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train + Valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{BASE_PATH}/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eeg_path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{BASE_PATH}/train_eegs/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eeg_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.parquet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spec_path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{BASE_PATH}/train_spectrograms/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spectrogram_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.parquet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spec2_path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{SPEC_DIR}/train_spectrograms/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spectrogram_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../hms-harmful-brain-activity-classification/train.csv'"
          ]
        }
      ],
      "source": [
        "# Train + Valid\n",
        "df = pd.read_csv(f'{BASE_PATH}/train.csv')\n",
        "df['eeg_path'] = f'{BASE_PATH}/train_eegs/'+df['eeg_id'].astype(str)+'.parquet'\n",
        "df['spec_path'] = f'{BASE_PATH}/train_spectrograms/'+df['spectrogram_id'].astype(str)+'.parquet'\n",
        "df['spec2_path'] = f'{SPEC_DIR}/train_spectrograms/'+df['spectrogram_id'].astype(str)+'.npy'\n",
        "df['class_name'] = df.expert_consensus.copy()\n",
        "df['class_label'] = df.expert_consensus.map(CFG.name2label)\n",
        "display(df.head(2))\n",
        "\n",
        "# Test\n",
        "test_df = pd.read_csv(f'{BASE_PATH}/test.csv')\n",
        "test_df['eeg_path'] = f'{BASE_PATH}/test_eegs/'+test_df['eeg_id'].astype(str)+'.parquet'\n",
        "test_df['spec_path'] = f'{BASE_PATH}/test_spectrograms/'+test_df['spectrogram_id'].astype(str)+'.parquet'\n",
        "test_df['spec2_path'] = f'{SPEC_DIR}/test_spectrograms/'+test_df['spectrogram_id'].astype(str)+'.npy'\n",
        "display(test_df.head(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtzpdI_v9mSx"
      },
      "source": [
        "## Convert `.parquet` to `.npy`\n",
        "\n",
        "To facilitate easier data loading, we will convert the EEG spectrograms from `parquet` to `npy` format. This process involves saving the spectrogram data, and since the content of the files remains the same, no significant changes are made.\n",
        "\n",
        "> It's worth noting that the `time` column is excluded, as it is not part of the spectrogram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-01T08:11:57.143667Z",
          "iopub.status.busy": "2024-02-01T08:11:57.143405Z",
          "iopub.status.idle": "2024-02-01T08:14:58.676582Z",
          "shell.execute_reply": "2024-02-01T08:14:58.675463Z",
          "shell.execute_reply.started": "2024-02-01T08:11:57.143644Z"
        },
        "papermill": {
          "duration": 0.86264,
          "end_time": "2024-01-14T03:18:01.346487",
          "exception": false,
          "start_time": "2024-01-14T03:18:00.483847",
          "status": "completed"
        },
        "tags": [],
        "id": "DESBNpMy9mSy"
      },
      "outputs": [],
      "source": [
        "# Define a function to process a single eeg_id\n",
        "def process_spec(spec_id, split=\"train\"):\n",
        "    spec_path = f\"{BASE_PATH}/{split}_spectrograms/{spec_id}.parquet\"\n",
        "    spec = pd.read_parquet(spec_path)\n",
        "    spec = spec.fillna(0).values[:, 1:].T # fill NaN values with 0, transpose for (Time, Freq) -> (Freq, Time)\n",
        "    spec = spec.astype(\"float32\")\n",
        "    np.save(f\"{SPEC_DIR}/{split}_spectrograms/{spec_id}.npy\", spec)\n",
        "\n",
        "# Get unique spec_ids of train and valid data\n",
        "spec_ids = df[\"spectrogram_id\"].unique()\n",
        "\n",
        "# Parallelize the processing using joblib for training data\n",
        "_ = joblib.Parallel(n_jobs=-1, backend=\"loky\")(\n",
        "    joblib.delayed(process_spec)(spec_id, \"train\")\n",
        "    for spec_id in tqdm(spec_ids, total=len(spec_ids))\n",
        ")\n",
        "\n",
        "# Get unique spec_ids of test data\n",
        "test_spec_ids = test_df[\"spectrogram_id\"].unique()\n",
        "\n",
        "# Parallelize the processing using joblib for test data\n",
        "_ = joblib.Parallel(n_jobs=-1, backend=\"loky\")(\n",
        "    joblib.delayed(process_spec)(spec_id, \"test\")\n",
        "    for spec_id in tqdm(test_spec_ids, total=len(test_spec_ids))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.011843,
          "end_time": "2024-01-14T03:18:01.457956",
          "exception": false,
          "start_time": "2024-01-14T03:18:01.446113",
          "status": "completed"
        },
        "tags": [],
        "id": "HdjHFxEi9mSy"
      },
      "source": [
        "# 🍚 | DataLoader\n",
        "\n",
        "This DataLoader first reads `npy` spectrogram files and extracts labeled subsamples using specified `offset` values. Then, it converts the spectrogram data into `log spectrogram` and applies the popular signal augmentation `MixUp`.\n",
        "\n",
        "> Note that, we are converting the mono channel signal to a 3-channel signal for using \"ImageNet\" weights of pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-01T08:17:27.279117Z",
          "iopub.status.busy": "2024-02-01T08:17:27.278733Z",
          "iopub.status.idle": "2024-02-01T08:17:27.300354Z",
          "shell.execute_reply": "2024-02-01T08:17:27.299141Z",
          "shell.execute_reply.started": "2024-02-01T08:17:27.279091Z"
        },
        "papermill": {
          "duration": 0.039133,
          "end_time": "2024-01-14T03:18:01.509017",
          "exception": false,
          "start_time": "2024-01-14T03:18:01.469884",
          "status": "completed"
        },
        "tags": [],
        "id": "yRuYuSeW9mSz"
      },
      "outputs": [],
      "source": [
        "def build_augmenter(dim=CFG.image_size):\n",
        "    augmenters = [\n",
        "        keras_cv.layers.MixUp(alpha=2.0),\n",
        "        keras_cv.layers.RandomCutout(height_factor=(1.0, 1.0),\n",
        "                                     width_factor=(0.06, 0.1)), # freq-masking\n",
        "        keras_cv.layers.RandomCutout(height_factor=(0.06, 0.1),\n",
        "                                     width_factor=(1.0, 1.0)), # time-masking\n",
        "    ]\n",
        "\n",
        "    def augment(img, label):\n",
        "        data = {\"images\":img, \"labels\":label}\n",
        "        for augmenter in augmenters:\n",
        "            if tf.random.uniform([]) < 0.5:\n",
        "                data = augmenter(data, training=True)\n",
        "        return data[\"images\"], data[\"labels\"]\n",
        "\n",
        "    return augment\n",
        "\n",
        "\n",
        "def build_decoder(with_labels=True, target_size=CFG.image_size, dtype=32):\n",
        "    def decode_signal(path, offset=None):\n",
        "        # Read .npy files and process the signal\n",
        "        file_bytes = tf.io.read_file(path)\n",
        "        sig = tf.io.decode_raw(file_bytes, tf.float32)\n",
        "        sig = sig[1024//dtype:]  # Remove header tag\n",
        "        sig = tf.reshape(sig, [400, -1])\n",
        "\n",
        "        # Extract labeled subsample from full spectrogram using \"offset\"\n",
        "        if offset is not None:\n",
        "            offset = offset // 2  # Only odd values are given\n",
        "            sig = sig[:, offset:offset+300]\n",
        "\n",
        "            # Pad spectrogram to ensure the same input shape of [400, 300]\n",
        "            pad_size = tf.math.maximum(0, 300 - tf.shape(sig)[1])\n",
        "            sig = tf.pad(sig, [[0, 0], [0, pad_size]])\n",
        "            sig = tf.reshape(sig, [400, 300])\n",
        "\n",
        "        # Log spectrogram\n",
        "        sig = tf.clip_by_value(sig, tf.math.exp(-4.0), tf.math.exp(8.0)) # avoid 0 in log\n",
        "        sig = tf.math.log(sig)\n",
        "\n",
        "        # Normalize spectrogram\n",
        "        sig -= tf.math.reduce_mean(sig)\n",
        "        sig /= tf.math.reduce_std(sig) + 1e-6\n",
        "\n",
        "        # Mono channel to 3 channels to use \"ImageNet\" weights\n",
        "        sig = tf.tile(sig[..., None], [1, 1, 3])\n",
        "        return sig\n",
        "\n",
        "    def decode_label(label):\n",
        "        label = tf.one_hot(label, CFG.num_classes)\n",
        "        label = tf.cast(label, tf.float32)\n",
        "        label = tf.reshape(label, [CFG.num_classes])\n",
        "        return label\n",
        "\n",
        "    def decode_with_labels(path, offset=None, label=None):\n",
        "        sig = decode_signal(path, offset)\n",
        "        label = decode_label(label)\n",
        "        return (sig, label)\n",
        "\n",
        "    return decode_with_labels if with_labels else decode_signal\n",
        "\n",
        "\n",
        "def build_dataset(paths, offsets=None, labels=None, batch_size=32, cache=True,\n",
        "                  decode_fn=None, augment_fn=None,\n",
        "                  augment=False, repeat=True, shuffle=1024,\n",
        "                  cache_dir=\"\", drop_remainder=False):\n",
        "    if cache_dir != \"\" and cache is True:\n",
        "        os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "    if decode_fn is None:\n",
        "        decode_fn = build_decoder(labels is not None)\n",
        "\n",
        "    if augment_fn is None:\n",
        "        augment_fn = build_augmenter()\n",
        "\n",
        "    AUTO = tf.data.experimental.AUTOTUNE\n",
        "    slices = (paths, offsets) if labels is None else (paths, offsets, labels)\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices(slices)\n",
        "    ds = ds.map(decode_fn, num_parallel_calls=AUTO)\n",
        "    ds = ds.cache(cache_dir) if cache else ds\n",
        "    ds = ds.repeat() if repeat else ds\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(shuffle, seed=CFG.seed)\n",
        "        opt = tf.data.Options()\n",
        "        opt.experimental_deterministic = False\n",
        "        ds = ds.with_options(opt)\n",
        "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n",
        "    ds = ds.map(augment_fn, num_parallel_calls=AUTO) if augment else ds\n",
        "    ds = ds.prefetch(AUTO)\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.012174,
          "end_time": "2024-01-14T03:18:01.538524",
          "exception": false,
          "start_time": "2024-01-14T03:18:01.52635",
          "status": "completed"
        },
        "tags": [],
        "id": "uJDl7hyp9mSz"
      },
      "source": [
        "# 🔪 | Data Split\n",
        "\n",
        "In the following code snippet, the data is divided into `5` folds. Note that, the `groups` argument is used to prevent any overlap of patients between the training and validation sets, thus avoiding potential **data leakage** issues. Additionally, each split is stratified based on the `class_label`, ensuring a uniform distribution of class labels in each fold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-01T08:14:58.702904Z",
          "iopub.status.busy": "2024-02-01T08:14:58.702622Z",
          "iopub.status.idle": "2024-02-01T08:15:01.163856Z",
          "shell.execute_reply": "2024-02-01T08:15:01.162898Z",
          "shell.execute_reply.started": "2024-02-01T08:14:58.702882Z"
        },
        "papermill": {
          "duration": 0.037496,
          "end_time": "2024-01-14T03:18:01.587924",
          "exception": false,
          "start_time": "2024-01-14T03:18:01.550428",
          "status": "completed"
        },
        "tags": [],
        "id": "ssGR1Ctb9mS0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "\n",
        "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=CFG.seed)\n",
        "\n",
        "df[\"fold\"] = -1\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "for fold, (train_idx, valid_idx) in enumerate(\n",
        "    sgkf.split(df, y=df[\"class_label\"], groups=df[\"patient_id\"])\n",
        "):\n",
        "    df.loc[valid_idx, \"fold\"] = fold\n",
        "df.groupby([\"fold\", \"class_name\"])[[\"eeg_id\"]].count().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.011875,
          "end_time": "2024-01-14T03:18:01.611955",
          "exception": false,
          "start_time": "2024-01-14T03:18:01.60008",
          "status": "completed"
        },
        "tags": [],
        "id": "q_9_jRtd9mS0"
      },
      "source": [
        "## Build Train & Valid Dataset\n",
        "\n",
        "Only first sample for each `spectrogram_id` is used in order to keep the dataset size managable. Feel free to train on full data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-01T08:17:29.652748Z",
          "iopub.status.busy": "2024-02-01T08:17:29.652278Z",
          "iopub.status.idle": "2024-02-01T08:17:30.626157Z",
          "shell.execute_reply": "2024-02-01T08:17:30.625103Z",
          "shell.execute_reply.started": "2024-02-01T08:17:29.652709Z"
        },
        "id": "iNf2dzgu9mS1"
      },
      "outputs": [],
      "source": [
        "# Sample from full data\n",
        "sample_df = df.groupby(\"spectrogram_id\").head(1).reset_index(drop=True)\n",
        "train_df = sample_df[sample_df.fold != CFG.fold]\n",
        "valid_df = sample_df[sample_df.fold == CFG.fold]\n",
        "print(f\"# Num Train: {len(train_df)} | Num Valid: {len(valid_df)}\")\n",
        "\n",
        "# Train\n",
        "train_paths = train_df.spec2_path.values\n",
        "train_offsets = train_df.spectrogram_label_offset_seconds.values.astype(int)\n",
        "train_labels = train_df.class_label.values\n",
        "train_ds = build_dataset(train_paths, train_offsets, train_labels, batch_size=CFG.batch_size,\n",
        "                         repeat=True, shuffle=True, augment=True, cache=True)\n",
        "\n",
        "# Valid\n",
        "valid_paths = valid_df.spec2_path.values\n",
        "valid_offsets = valid_df.spectrogram_label_offset_seconds.values.astype(int)\n",
        "valid_labels = valid_df.class_label.values\n",
        "valid_ds = build_dataset(valid_paths, valid_offsets, valid_labels, batch_size=CFG.batch_size,\n",
        "                         repeat=False, shuffle=False, augment=False, cache=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8VCKaDY9mS1"
      },
      "source": [
        "## Dataset Check\n",
        "\n",
        "Let's visualize some samples from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2024-02-01T08:17:33.806415Z",
          "iopub.status.busy": "2024-02-01T08:17:33.806036Z",
          "iopub.status.idle": "2024-02-01T08:17:37.720083Z",
          "shell.execute_reply": "2024-02-01T08:17:37.718626Z",
          "shell.execute_reply.started": "2024-02-01T08:17:33.806385Z"
        },
        "id": "QHHr2Z999mS2"
      },
      "outputs": [],
      "source": [
        "imgs, tars = next(iter(train_ds))\n",
        "\n",
        "num_imgs = 8\n",
        "plt.figure(figsize=(4*4, num_imgs//4*5))\n",
        "for i in range(num_imgs):\n",
        "    plt.subplot(num_imgs//4, 4, i + 1)\n",
        "    img = imgs[i].numpy()[...,0]  # Adjust as per your image data format\n",
        "    img -= img.min()\n",
        "    img /= img.max() + 1e-4\n",
        "    tar = CFG.label2name[np.argmax(tars[i].numpy())]\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Target: {tar}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v1Ix9nb9mS2"
      },
      "source": [
        "# 🔍 | Loss & Metric\n",
        "\n",
        "The evaluation metric in this competition is **KL Divergence**, defined as,\n",
        "\n",
        "$$\n",
        "D_{\\text{KL}}(P \\parallel Q) = \\sum_{i} P(i) \\log\\left(\\frac{P(i)}{Q(i)}\\right)\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $P$ is the true distribution.\n",
        "- $Q$ is the predicted distribution.\n",
        "\n",
        "Interestingly, as KL Divergence is differentiable, we can directly use it as our loss function. Thus, we don't need to use a third-party metric like **Accuracy** to evaluate our model. Therefore, `valid_loss` can stand alone as an indicator for our evaluation. In keras, we already have impelementation for KL Divergence loss so we only need to import it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T08:11:23.764307Z",
          "iopub.status.busy": "2024-01-21T08:11:23.763944Z",
          "iopub.status.idle": "2024-01-21T08:11:23.770792Z",
          "shell.execute_reply": "2024-01-21T08:11:23.768924Z",
          "shell.execute_reply.started": "2024-01-21T08:11:23.764273Z"
        },
        "id": "wF5djv5y9mS3"
      },
      "outputs": [],
      "source": [
        "LOSS = keras.losses.KLDivergence()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.016849,
          "end_time": "2024-01-14T03:18:38.613991",
          "exception": false,
          "start_time": "2024-01-14T03:18:38.597142",
          "status": "completed"
        },
        "tags": [],
        "id": "9HTJwvLQ9mS3"
      },
      "source": [
        "# 🤖 | Modeling\n",
        "\n",
        "This notebook uses the `EfficientNetV2 B2` from KerasCV's collection of pretrained models. To explore other models, simply modify the `preset` in the `CFG` (config). Check the [KerasCV website](https://keras.io/api/keras_cv/models/tasks/image_classifier/) for a list of available pretrained models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T08:11:23.772146Z",
          "iopub.status.busy": "2024-01-21T08:11:23.771871Z",
          "iopub.status.idle": "2024-01-21T08:11:47.907132Z",
          "shell.execute_reply": "2024-01-21T08:11:47.906227Z",
          "shell.execute_reply.started": "2024-01-21T08:11:23.77212Z"
        },
        "papermill": {
          "duration": 10.446166,
          "end_time": "2024-01-14T03:18:49.186176",
          "exception": false,
          "start_time": "2024-01-14T03:18:38.74001",
          "status": "completed"
        },
        "tags": [],
        "id": "REmjdy5_9mS3"
      },
      "outputs": [],
      "source": [
        "# Build Classifier\n",
        "model = keras_cv.models.ImageClassifier.from_preset(\n",
        "    CFG.preset, num_classes=CFG.num_classes\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss=LOSS)\n",
        "\n",
        "# Model Sumamry\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.016209,
          "end_time": "2024-01-14T03:18:49.21924",
          "exception": false,
          "start_time": "2024-01-14T03:18:49.203031",
          "status": "completed"
        },
        "tags": [],
        "id": "elyR2sIL9mS4"
      },
      "source": [
        "# ⚓ | LR Schedule\n",
        "\n",
        "A well-structured learning rate schedule is essential for efficient model training, ensuring optimal convergence and avoiding issues such as overshooting or stagnation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T08:11:47.908637Z",
          "iopub.status.busy": "2024-01-21T08:11:47.908346Z",
          "iopub.status.idle": "2024-01-21T08:11:47.918578Z",
          "shell.execute_reply": "2024-01-21T08:11:47.917684Z",
          "shell.execute_reply.started": "2024-01-21T08:11:47.90861Z"
        },
        "papermill": {
          "duration": 0.028945,
          "end_time": "2024-01-14T03:18:49.264535",
          "exception": false,
          "start_time": "2024-01-14T03:18:49.23559",
          "status": "completed"
        },
        "tags": [],
        "id": "6UsHQtcf9mS4"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n",
        "    lr_start, lr_max, lr_min = 5e-5, 6e-6 * batch_size, 1e-5\n",
        "    lr_ramp_ep, lr_sus_ep, lr_decay = 3, 0, 0.75\n",
        "\n",
        "    def lrfn(epoch):  # Learning rate update function\n",
        "        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
        "        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n",
        "        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
        "        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n",
        "        elif mode == 'cos':\n",
        "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n",
        "            phase = math.pi * decay_epoch_index / decay_total_epochs\n",
        "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n",
        "        return lr\n",
        "\n",
        "    if plot:  # Plot lr curve if plot is True\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n",
        "        plt.xlabel('epoch'); plt.ylabel('lr')\n",
        "        plt.title('LR Scheduler')\n",
        "        plt.show()\n",
        "\n",
        "    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T08:11:47.920059Z",
          "iopub.status.busy": "2024-01-21T08:11:47.919711Z",
          "iopub.status.idle": "2024-01-21T08:11:48.208939Z",
          "shell.execute_reply": "2024-01-21T08:11:48.207965Z",
          "shell.execute_reply.started": "2024-01-21T08:11:47.920032Z"
        },
        "papermill": {
          "duration": 0.297147,
          "end_time": "2024-01-14T03:18:49.578089",
          "exception": false,
          "start_time": "2024-01-14T03:18:49.280942",
          "status": "completed"
        },
        "tags": [],
        "id": "PdfcPgFW9mS4"
      },
      "outputs": [],
      "source": [
        "lr_cb = get_lr_callback(CFG.batch_size, mode=CFG.lr_mode, plot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.017199,
          "end_time": "2024-01-14T03:18:49.613648",
          "exception": false,
          "start_time": "2024-01-14T03:18:49.596449",
          "status": "completed"
        },
        "tags": [],
        "id": "bnavUPnF9mS5"
      },
      "source": [
        "# 💾 | Model Checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T08:11:48.210551Z",
          "iopub.status.busy": "2024-01-21T08:11:48.210251Z",
          "iopub.status.idle": "2024-01-21T08:11:48.21519Z",
          "shell.execute_reply": "2024-01-21T08:11:48.214326Z",
          "shell.execute_reply.started": "2024-01-21T08:11:48.210525Z"
        },
        "papermill": {
          "duration": 0.024529,
          "end_time": "2024-01-14T03:18:49.655708",
          "exception": false,
          "start_time": "2024-01-14T03:18:49.631179",
          "status": "completed"
        },
        "tags": [],
        "id": "MJArbGe-9mS5"
      },
      "outputs": [],
      "source": [
        "ckpt_cb = keras.callbacks.ModelCheckpoint(\"best_model.keras\",\n",
        "                                         monitor='val_loss',\n",
        "                                         save_best_only=True,\n",
        "                                         save_weights_only=False,\n",
        "                                         mode='min')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.01671,
          "end_time": "2024-01-14T03:18:49.689354",
          "exception": false,
          "start_time": "2024-01-14T03:18:49.672644",
          "status": "completed"
        },
        "tags": [],
        "id": "0qAAIym19mS5"
      },
      "source": [
        "# 🚂 | Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T08:11:48.216638Z",
          "iopub.status.busy": "2024-01-21T08:11:48.216319Z",
          "iopub.status.idle": "2024-01-21T08:26:11.991931Z",
          "shell.execute_reply": "2024-01-21T08:26:11.990786Z",
          "shell.execute_reply.started": "2024-01-21T08:11:48.216588Z"
        },
        "papermill": {
          "duration": 3374.692199,
          "end_time": "2024-01-14T04:15:04.398389",
          "exception": false,
          "start_time": "2024-01-14T03:18:49.70619",
          "status": "completed"
        },
        "tags": [],
        "id": "YU2HNN3W9mS5"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=CFG.epochs,\n",
        "    callbacks=[lr_cb, ckpt_cb],\n",
        "    steps_per_epoch=len(train_df)//CFG.batch_size,\n",
        "    validation_data=valid_ds,\n",
        "    verbose=CFG.verbose\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.693309,
          "end_time": "2024-01-14T04:15:05.731839",
          "exception": false,
          "start_time": "2024-01-14T04:15:05.03853",
          "status": "completed"
        },
        "tags": [],
        "id": "15FIkhn_9mS6"
      },
      "source": [
        "# 🧪 | Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.632183,
          "end_time": "2024-01-14T04:15:06.991143",
          "exception": false,
          "start_time": "2024-01-14T04:15:06.35896",
          "status": "completed"
        },
        "tags": [],
        "id": "IV6c2_d19mS6"
      },
      "source": [
        "## Load Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T08:26:11.994508Z",
          "iopub.status.busy": "2024-01-21T08:26:11.994138Z",
          "iopub.status.idle": "2024-01-21T08:26:19.318291Z",
          "shell.execute_reply": "2024-01-21T08:26:19.317485Z",
          "shell.execute_reply.started": "2024-01-21T08:26:11.994479Z"
        },
        "papermill": {
          "duration": 20.428261,
          "end_time": "2024-01-14T04:15:28.044401",
          "exception": false,
          "start_time": "2024-01-14T04:15:07.61614",
          "status": "completed"
        },
        "tags": [],
        "id": "4WR1f9KX9mS6"
      },
      "outputs": [],
      "source": [
        "model.load_weights(\"best_model.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.703901,
          "end_time": "2024-01-14T04:20:09.745279",
          "exception": false,
          "start_time": "2024-01-14T04:20:09.041378",
          "status": "completed"
        },
        "tags": [],
        "id": "BD5gie1k9mS7"
      },
      "source": [
        "## Build Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T08:26:19.320511Z",
          "iopub.status.busy": "2024-01-21T08:26:19.320221Z",
          "iopub.status.idle": "2024-01-21T08:26:19.366196Z",
          "shell.execute_reply": "2024-01-21T08:26:19.365433Z",
          "shell.execute_reply.started": "2024-01-21T08:26:19.320486Z"
        },
        "id": "3vH6kYzH9mS7"
      },
      "outputs": [],
      "source": [
        "test_paths = test_df.spec2_path.values\n",
        "test_ds = build_dataset(test_paths, batch_size=min(CFG.batch_size, len(test_df)),\n",
        "                         repeat=False, shuffle=False, cache=False, augment=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbirUhDw9mS7"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T08:26:19.367983Z",
          "iopub.status.busy": "2024-01-21T08:26:19.367379Z",
          "iopub.status.idle": "2024-01-21T08:26:44.828629Z",
          "shell.execute_reply": "2024-01-21T08:26:44.827887Z",
          "shell.execute_reply.started": "2024-01-21T08:26:19.367955Z"
        },
        "id": "p8BhWVZK9mS7"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyBGchDh9mS8"
      },
      "source": [
        "# 📩 | Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T08:26:44.830386Z",
          "iopub.status.busy": "2024-01-21T08:26:44.830108Z",
          "iopub.status.idle": "2024-01-21T08:26:44.873794Z",
          "shell.execute_reply": "2024-01-21T08:26:44.872998Z",
          "shell.execute_reply.started": "2024-01-21T08:26:44.830361Z"
        },
        "id": "chbgcaHb9mS8"
      },
      "outputs": [],
      "source": [
        "pred_df = test_df[[\"eeg_id\"]].copy()\n",
        "target_cols = [x.lower()+'_vote' for x in CFG.class_names]\n",
        "pred_df[target_cols] = preds.tolist()\n",
        "\n",
        "sub_df = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')\n",
        "sub_df = sub_df[[\"eeg_id\"]].copy()\n",
        "sub_df = sub_df.merge(pred_df, on=\"eeg_id\", how=\"left\")\n",
        "sub_df.to_csv(\"submission.csv\", index=False)\n",
        "sub_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JivIKi9c9mS8"
      },
      "source": [
        "# 📌 | Reference\n",
        "* [HMS-HBAC: ResNet34d Baseline [Training]](https://www.kaggle.com/code/ttahara/hms-hbac-resnet34d-baseline-training)\n",
        "* [EfficientNetB2 Starter - [LB 0.57]](https://www.kaggle.com/code/cdeotte/efficientnetb2-starter-lb-0-57)"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "databundleVersionId": 7469972,
          "sourceId": 59093,
          "sourceType": "competition"
        },
        {
          "datasetId": 4308295,
          "sourceId": 7526248,
          "sourceType": "datasetVersion"
        },
        {
          "modelInstanceId": 4598,
          "sourceId": 6127,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 3846.080383,
      "end_time": "2024-01-14T04:20:19.064569",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-01-14T03:16:12.984186",
      "version": "2.4.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}